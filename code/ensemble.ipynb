{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf69a6f-ca5f-40f2-9337-3ecc69ec1e6c",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47aa479-b860-46c9-b82c-aa4685cc8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from load_data import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle as pickle\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "# SKT KoBERT\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gluonnlp as nlp\n",
    "\n",
    "from ipywidgets import FloatProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6331056-48f6-4315-b6ed-67fb85894ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace Inference Functions\n",
    "def inference_huggingface(model, tokenized_sent, device):\n",
    "    dataloader = DataLoader(tokenized_sent, batch_size=40, shuffle=False)\n",
    "    model.eval()\n",
    "    output_logits = []\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            if 'token_type_ids' in data.keys():\n",
    "                outputs = model(\n",
    "                    input_ids=data['input_ids'].to(device),\n",
    "                    attention_mask=data['attention_mask'].to(device),\n",
    "                    token_type_ids=data['token_type_ids'].to(device)\n",
    "                )\n",
    "            else:\n",
    "                outputs = model(\n",
    "                    input_ids=data['input_ids'].to(device),\n",
    "                    attention_mask=data['attention_mask'].to(device)\n",
    "                )\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        output_logits.append(logits)\n",
    "    return np.concatenate(output_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f91124ba-db89-4458-a52a-df92c73e3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset(dataset_dir, tokenizer):\n",
    "    test_dataset = load_data(dataset_dir)\n",
    "    test_label = test_dataset['label'].values\n",
    "    # tokenizing dataset\n",
    "    tokenized_test = tokenized_dataset(test_dataset, tokenizer)\n",
    "    return tokenized_test, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc9fd63-3b59-428d-8852-6381974db340",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_dir = \"/opt/ml/input/data/test/test.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c66397ec-aad5-4734-a907-39feadfecab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(cfg_file):\n",
    "    print(\"CURR cfg_file: {}\".format(cfg_file))\n",
    "    with open(cfg_file) as f:\n",
    "        cfg = json.load(f)\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    # load tokenizer\n",
    "    TOK_NAME = cfg[\"model_name\"]\n",
    "    #TODO: kobert에 대해 따로 처리할 것\n",
    "    tokenizer = AutoTokenizer.from_pretrained(TOK_NAME)\n",
    "\n",
    "    # load my model\n",
    "    MODEL_NAME = cfg[\"output_dir\"] # model dir.\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        os.path.join(MODEL_NAME, \"checkpoint-{}\".format(cfg[\"num_train_epochs\"] * 550)))\n",
    "    model.parameters\n",
    "    model.to(device)\n",
    "\n",
    "    # load test datset\n",
    "    #test_dataset_dir = \"/opt/ml/input/data/test/test.tsv\"\n",
    "    test_dataset, test_label = load_test_dataset(test_dataset_dir, tokenizer)\n",
    "    test_dataset = RE_Dataset(test_dataset ,test_label)\n",
    "\n",
    "    # predict answer\n",
    "    #print(\"Start prediction...\")\n",
    "    pred_answer = inference_huggingface(model, test_dataset, device)\n",
    "    \n",
    "    return pred_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff664e4-0241-4632-8d41-83be5ca2f0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURR cfg_file: configs/bert-seed-7-epoch-20.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/code/load_data.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = get_logits('configs/bert-seed-7-epoch-20.json')\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7deb1b60-7b76-4b9b-b898-8ee5f27f3222",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_huggingface = [\n",
    "    #TODO: 앙상블에 사용할 모델 목록\n",
    "    'configs/roberta.json',\n",
    "    'configs/bert-seed-7-epoch-20.json',\n",
    "    'configs/koelectra-epoch-20.json',\n",
    "    'configs/kobert-epoch-20.json'\n",
    "]\n",
    "\n",
    "model_path_kobert = [\n",
    "    #TODO: 앙상블에 사용할 모델 목록\n",
    "    '/opt/ml/model/model_skt-kobert-both-label.pt', # 20\n",
    "    '/opt/ml/model/model_skt-kobert-both-label-seed-7.pt', # 21\n",
    "    '/opt/ml/model/model_kobert_0_2_epoch_10.pt', # 18\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd5a3263-20a3-485d-951e-2c3587862326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURR cfg_file: configs/roberta.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bbad7f9c714d5aa27853e505e7ca5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e74f6d8b944a4db1e1a01eb322272e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a8fb4f783940a59c27817f18f8850f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=9096718.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURR cfg_file: configs/bert-seed-7-epoch-20.json\n",
      "CURR cfg_file: configs/koelectra-epoch-20.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c2fa1c597b4095a3c5d5bf75bbadb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f715de4a1d54429ba0cb268d83c55cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=263326.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdc5e90b56d494eab97ba142e25b2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=61.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURR cfg_file: configs/kobert-epoch-20.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f6d947a34941e3b8309f33bae80ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=426.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1843de40db80430a80c51de37a1e83f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=77779.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aee48afcdd2437aa690feec0531cc8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=51.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2.914875  ,  0.3328355 ,  6.9130335 , ..., -1.0136776 ,\n",
       "         -1.067852  , -0.56732583],\n",
       "        [ 0.9859098 , -0.2885439 ,  0.08498568, ..., -0.75621104,\n",
       "         -0.5908805 , -0.7222718 ],\n",
       "        [ 1.0534576 ,  2.995008  , -1.5576702 , ..., -0.58633024,\n",
       "         -0.6264167 , -0.72085637],\n",
       "        ...,\n",
       "        [ 1.0475044 , -0.34612644, -0.02586268, ..., -0.6742935 ,\n",
       "         -0.6050735 , -0.7355977 ],\n",
       "        [ 7.53278   ,  0.17950976,  0.7187565 , ..., -1.7230488 ,\n",
       "         -2.1267328 , -1.5935761 ],\n",
       "        [ 6.6731253 , -0.43922174,  0.38256612, ..., -1.1662935 ,\n",
       "         -1.8269639 , -1.6029122 ]], dtype=float32),\n",
       " array([[ 5.0713735 ,  2.6281214 ,  8.673834  , ..., -2.2970295 ,\n",
       "         -2.1820421 , -2.2649179 ],\n",
       "        [ 1.168229  , -1.6565453 ,  0.5646994 , ..., -0.23038615,\n",
       "         -1.4705226 , -1.7014961 ],\n",
       "        [ 0.03604685, 10.674938  , -0.21921825, ..., -2.0160847 ,\n",
       "          0.06821638, -1.0548279 ],\n",
       "        ...,\n",
       "        [ 2.4257016 , -1.9017417 ,  0.12067461, ..., -0.6590364 ,\n",
       "         -1.7340732 , -2.0809376 ],\n",
       "        [ 9.354839  ,  0.86043066, -0.90931183, ..., -4.860645  ,\n",
       "         -2.3965197 , -3.2296681 ],\n",
       "        [12.639496  , -0.7009586 , -0.95134723, ..., -3.9557762 ,\n",
       "         -3.8481646 , -3.0391917 ]], dtype=float32),\n",
       " array([[  3.9215283 ,  -2.0033197 ,   8.141437  , ...,  -6.104636  ,\n",
       "          -7.9375257 ,  -2.568304  ],\n",
       "        [  2.7635229 ,  -5.007679  ,   0.25293857, ...,  -4.999553  ,\n",
       "          -7.5036983 ,  -6.09426   ],\n",
       "        [ -4.428046  ,  11.014505  ,  -2.573688  , ...,  -3.4002771 ,\n",
       "          -3.7319794 ,   0.27339327],\n",
       "        ...,\n",
       "        [  2.1823652 ,  -5.4012628 ,  -0.68514806, ...,  -4.7731853 ,\n",
       "          -7.4377112 ,  -6.1498823 ],\n",
       "        [ 12.00046   ,  -5.7607546 ,  -3.9576156 , ...,  -9.75607   ,\n",
       "         -12.089678  ,  -9.495432  ],\n",
       "        [  6.9134474 ,  -6.690097  ,  -2.5797696 , ...,  -4.3481245 ,\n",
       "         -10.73381   ,  -7.401488  ]], dtype=float32),\n",
       " array([[10.43761   , -1.3834131 , -0.05528098, ..., -4.697129  ,\n",
       "         -4.037641  , -5.2588205 ],\n",
       "        [ 9.292372  , -1.7405733 , -1.8732958 , ..., -4.2372437 ,\n",
       "         -3.582362  , -5.58739   ],\n",
       "        [ 7.043908  , -1.2492427 , -2.3292272 , ..., -3.1095572 ,\n",
       "         -2.8031528 , -4.1641    ],\n",
       "        ...,\n",
       "        [ 8.728949  , -1.3993673 , -0.7882285 , ..., -3.962769  ,\n",
       "         -3.5062807 , -4.740626  ],\n",
       "        [ 8.849468  , -1.3388295 , -1.9574432 , ..., -4.2289143 ,\n",
       "         -3.4342089 , -4.9343023 ],\n",
       "        [ 9.864256  , -1.1460768 , -2.6805196 , ..., -4.5160265 ,\n",
       "         -3.6290889 , -5.499363  ]], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HuggingFace\n",
    "results = []\n",
    "\n",
    "for path in model_path_huggingface:\n",
    "    results.append(get_logits(path))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bbfe040-afb1-48cb-b232-8e1d698a4f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(results).sum(axis=0).argmax(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2afa60a-6e7d-4d8d-85db-9dcda62c2d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 10,  1,  0,  0,  0,  7,  0,  4, 20,  0,  0,  0,  8,  0,  0,  0,\n",
       "        0,  0,  0, 15,  0,  0, 27,  4,  4, 10,  0,  0, 21,  0,  4, 10, 21,\n",
       "        0,  0, 21,  4,  0,  0,  0,  0,  0, 25, 17,  0,  9,  2,  0, 15,  0,\n",
       "       10,  0,  2,  0, 15,  0,  0,  0, 10,  0, 33,  0, 17,  0,  2, 24,  0,\n",
       "       10,  0,  0,  0,  0, 10,  0,  0,  2, 15, 14,  0, 15,  0,  0, 10, 15,\n",
       "        0,  4,  6,  7,  0,  0, 12,  0,  0, 21,  0,  8,  0, 15,  9,  0,  2,\n",
       "        0, 21,  7,  0,  0,  7,  0,  0,  0,  2,  0,  0,  4,  0,  2,  0,  0,\n",
       "        0,  0,  0,  6,  0,  4, 20,  7,  0, 10, 15,  0,  0,  0,  0, 10,  0,\n",
       "       20,  0,  4,  0,  0, 10,  0, 10,  0, 15,  0, 10,  0,  9, 10, 21,  2,\n",
       "        8,  0,  0, 17,  0,  0,  0,  0,  0,  0, 10,  0,  0,  0, 21,  0,  0,\n",
       "       10,  0,  0,  0,  0,  0,  0, 27,  2,  0,  2,  0, 39,  2, 22,  0,  7,\n",
       "       10,  0, 25,  0,  5,  0, 20, 10,  0, 11, 10,  0, 15, 21, 24,  2,  0,\n",
       "        4,  0,  0, 27,  0,  0, 10,  7, 15,  0,  4,  0,  0,  5, 15,  0,  0,\n",
       "        0,  0, 10,  8,  0,  0,  2,  0,  0, 27,  4,  0,  0,  0,  0,  0,  0,\n",
       "       10,  0, 10,  0,  0,  0, 22,  0,  0,  0,  7,  0,  0,  0,  0,  5,  5,\n",
       "        8,  6, 10,  0,  0,  2, 17,  6,  4,  4,  0,  0,  0, 15,  0, 15,  0,\n",
       "        2,  7, 22, 10,  0,  8,  0,  0,  4,  1,  0,  2,  0, 10,  0, 10, 21,\n",
       "        2,  0,  0,  0, 10, 21,  0,  0,  0, 10,  0,  8,  0,  4,  0,  0,  0,\n",
       "        2,  4,  0,  0,  0,  0,  0,  0,  0, 15,  0, 15, 10,  6,  0,  0,  0,\n",
       "        4, 22, 15,  4,  0,  2, 21,  0,  0, 24,  0,  0,  4,  0, 10,  0, 33,\n",
       "        0,  0,  0, 24, 34,  0,  0,  0,  0, 27,  2,  2, 10,  0,  0,  4,  2,\n",
       "        0,  0,  0, 17,  7,  0,  0,  0, 10, 12,  0,  4,  0,  0,  0, 10,  0,\n",
       "        0,  4,  7,  0,  0,  8,  0,  0, 15,  0,  0,  0,  4,  0,  0, 10, 15,\n",
       "        0, 11, 15,  2,  0,  4,  0, 20,  0,  4,  0,  0,  0,  0,  0,  0,  5,\n",
       "        4, 11,  4,  0,  0,  0,  0,  2,  8, 10, 12,  0,  0,  0,  0,  0,  0,\n",
       "        2,  4,  0,  4,  0,  0, 10,  0,  0,  0,  0,  0,  0,  0, 10,  2,  0,\n",
       "        2,  0,  0,  4, 10,  0,  0,  0, 22,  0, 33, 10,  0,  0, 10,  0,  0,\n",
       "       30,  0, 10, 10,  0, 17,  0,  5,  0,  4,  0, 21,  0,  0,  0,  0,  0,\n",
       "        9,  0, 15, 10,  0,  0, 10, 10,  8,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "       22,  0,  0,  4,  0, 10,  0,  0,  0,  4,  0,  0,  4,  0,  6,  0,  0,\n",
       "       10,  0,  0, 10,  0, 19,  0,  0,  0,  0,  7, 10, 20,  0,  0,  0,  0,\n",
       "        5,  0,  5,  0,  4,  0, 10, 11,  0,  0,  0,  0,  0, 32,  0,  4,  0,\n",
       "       14, 33,  0,  2,  0,  9, 10, 24,  0,  0, 20,  0, 15,  0,  0,  2,  7,\n",
       "        2,  0, 15,  6,  0,  0,  0,  0,  8,  2,  0,  0,  6,  2,  8,  0,  0,\n",
       "        0,  0,  0,  0, 17, 24, 10,  0,  0,  0,  0, 15,  0,  0,  0, 33, 10,\n",
       "        1,  0, 33, 10,  2,  0, 17,  0, 10,  0, 10,  0,  2,  0,  0,  0,  0,\n",
       "        0,  0, 10, 11, 10,  0,  0, 10,  0,  6, 10,  0,  0, 15, 10,  0, 21,\n",
       "        0,  0,  0,  0, 23, 10, 27,  0,  0,  4,  4,  0,  0,  2, 15,  4, 21,\n",
       "        2,  4,  0,  0,  0,  0,  0,  0,  0, 10,  0,  2,  0, 10,  0,  0,  2,\n",
       "        7,  0,  0,  0,  9,  2,  5,  8,  4, 15, 10, 17, 24,  0,  0,  4,  4,\n",
       "        4,  0,  0,  0,  0, 15,  0,  6, 21, 20,  0,  0,  7,  0,  0,  0,  0,\n",
       "        4,  0,  2,  6,  6, 15,  8,  5, 10,  6, 10,  0,  9,  0,  0,  0,  0,\n",
       "        4,  0,  0,  0,  4,  4, 20, 10, 33,  0,  0,  0, 20, 17, 14,  0,  5,\n",
       "        0,  0,  2, 10, 21,  0, 17,  7,  1,  0,  2, 10,  0,  0,  2,  2, 21,\n",
       "        0,  0,  0, 15,  0,  0,  0,  0, 10,  0,  0,  0,  0,  0,  7,  0,  0,\n",
       "       24,  0,  0,  0,  0,  0,  4,  2,  0,  0,  4,  0,  4,  0, 17, 17,  0,\n",
       "       10,  0,  0,  4,  0,  0,  4,  0,  0,  0, 20,  0,  0,  0,  0,  0,  0,\n",
       "        4, 12,  0,  0,  9,  0,  0,  4,  4,  0,  0,  0,  0,  4, 10,  9, 20,\n",
       "        0, 10,  0,  0,  0,  0,  4, 20,  0,  0,  0,  0, 10,  0, 33,  0,  0,\n",
       "        0, 21,  0,  0,  7,  0, 14,  7,  0,  0,  0,  0,  8, 10,  0,  0,  0,\n",
       "       10,  2,  0, 21,  0,  0,  0, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "       20,  9,  0,  0,  0,  0,  0,  0,  0, 10, 27,  0, 22,  1,  0,  0,  0,\n",
       "       33,  0, 10, 10,  5,  0,  0,  0,  0,  0,  6, 24,  6,  0, 10,  0,  0,\n",
       "       10, 10,  4, 10,  5,  0, 10, 10, 33, 10, 10,  0, 33, 10,  0,  4,  0,\n",
       "        0,  0,  6,  0, 10, 10,  6,  2,  0,  2,  0,  0, 25, 10,  0,  2,  2,\n",
       "        0,  6, 23,  0,  0,  0,  0,  9,  0,  0, 10,  0,  0,  7,  0, 10,  4,\n",
       "        4,  0,  6,  0,  4,  0, 15,  1,  2,  0,  0,  4,  0,  0,  2, 15,  0,\n",
       "        4, 10,  0, 10,  0,  0,  7,  0, 10,  0,  0,  0,  0,  0, 10,  0,  4,\n",
       "        0,  0, 21,  2,  0, 22,  0,  6, 11,  0, 10, 10,  0,  0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(results).sum(axis=0).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fe7323c-6609-4179-b681-472402816284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 3.0.0\n",
      "Summary: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Sam Shleifer, Patrick von Platen, Google AI Language Team Authors, Open AI team Authors, Facebook AI Authors, Carnegie Mellon University Authors\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache\n",
      "Location: /opt/conda/lib/python3.7/site-packages\n",
      "Requires: packaging, sacremoses, filelock, regex, sentencepiece, requests, numpy, tokenizers, tqdm\n",
      "Required-by: kobart\n"
     ]
    }
   ],
   "source": [
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d827cfd-e208-4502-a90f-a9f84baaa548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKT KoBERT 관련 Classes\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "    \n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes = 42,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b368b430-f009-4aaa-bfe0-1be990c288a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "# SKT KoBERT inferencing code\n",
    "device = torch.device(\"cuda:0\")\n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "max_len = 128\n",
    "batch_size = 32\n",
    "warmup_ratio = 0.01\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "log_interval = 50\n",
    "learning_rate = 5e-5\n",
    "\n",
    "# Dataset 설정\n",
    "dataset_path = r\"/opt/ml/input/data/test/test.tsv\"\n",
    "dataset = load_data(dataset_path)\n",
    "dataset['sentence'] = dataset['entity_01'] + ' [SEP] ' + dataset['entity_02'] + ' [SEP] ' + dataset['sentence']\n",
    "dataset[['sentence','label']].to_csv(\"/opt/ml/input/data/test/test.txt\", sep='\\t', index=False)\n",
    "\n",
    "# Dataset Load\n",
    "dataset_test = nlp.data.TSVDataset(\"/opt/ml/input/data/test/test.txt\", field_indices=[0,1], num_discard_samples=1)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n",
    "\n",
    "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d863a7ff-e512-4f26-ab8b-5c7ed6bf8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in model_path_kobert:\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    Predict = []\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length = valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        Predict.extend(out.detach().cpu().numpy())\n",
    "    np.save('/opt/ml/logits/logit_{}.npy'.format(path.split(\"/\")[-1].split(\".\")[0]), Predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf29f0d-fcbe-4ff7-820e-310ce676ad46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Predict).argmax(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b43fb6e-dfbd-4a1b-b476-00d13c1ec36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURR cfg_file: /opt/ml/logits/logit_roberta_large-seed-26.npy\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-21c57e6e5aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/opt/ml/logits/logit_roberta_large-seed-26.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-b52a244f6fd0>\u001b[0m in \u001b[0;36mget_logits\u001b[0;34m(cfg_file)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CURR cfg_file: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# load tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c1896-cb7b-48e3-9443-b709a69f6164",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_answer = np.array(results).sum(axis=0).argmax(axis=1)\n",
    "\n",
    "\n",
    "output = pd.DataFrame(pred_answer, columns=['pred'])\n",
    "output.to_csv('./prediction/submission_{}.csv'.format(\"ensemble_huggingface\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f397ff32-4399-4a9a-9cb8-fb7ce22456ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e545611-a22c-4c31-b4b4-7da711b83260",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob('/opt/ml/logits/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87d89fae-5b0c-419e-ac53-77f1d9bdd0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 10  1  0  0  0  7  0  4 20  0  0  0  8  0  0  0  7  0 10 15  5  0 27\n",
      "  4  4 10  0  0 21  0  4 12 21 23  0 21  4  0  0  0  0  0  8 17  0  9  2\n",
      "  0 15  0 10  0  2  0 15  4  0  0 10  0 33  0 17  4  2 24  0 12  0  0  0\n",
      "  0 10  0  0  2 15 14  0  3  0  0 10 15  0  4  6  7  2  0 12  0 17 11  0\n",
      "  8 14 15 15 15  2  0 21  7  0  0  8  0  0  4  2  0  0  4  0  2  0  0  0\n",
      "  0 15  6  0  4 20  7  0 10 15  0  0  0  0 10  0 20  0  4  0  0 10  0 10\n",
      "  0 15  0 10 10  9 10 21  2  8  0  0 17  0  0  0  0  0  0 10  0 10  9  8\n",
      "  0  0 10  0  0 20 17  0  0 27  2  0  2  0 39  2 22  0  9 10  0 25  0  5\n",
      " 32 20 10  0  8 10  0 15  8 24  2  0  4  0  0 27  0 10 10  7 15  0  4  5\n",
      "  0  5 15  0  0  0  0 10  8  0  1  2  0  4 27  4  0  0  0  0  0  0 10  0\n",
      " 10  0  0  0 22  0  5  0  7 21  0  0  5  5  5  8  6 10 17  0  2 17  6  4\n",
      "  4  0  0  0 15  0 15  0  2  7 22  0  0  8  0  0  4  8  5  2  0 10  0 10\n",
      "  8  2 15  2  0 10  8  0  0  0 10  0  8  0  4  4  0  0  2  4  0  0  0 10\n",
      "  0  0  0 15  0 15 10  6  0  0  0  4 22 15  4  0  2  8  0  4 24  0  0  4\n",
      "  0 10  0 33  0  0  0 24 34  0  0  0  0 27  2  2 10  0  0  4  2  0  0  0\n",
      " 17  7  0  7  0 10 10 32  4  0  0  0 10  0  0  4  7  4  0  8  0  0 15  0\n",
      " 15  0  4  0  0 10 15  0 11  3  2  0  4  0 20  0  4  0  0  0  0  0 17  5\n",
      "  4 11  4  0  0  0  0  2  0 10 12  0  0  0  0  0  0  2  4  0  4  0  0 10\n",
      "  0  0  0 34  0  0  0 10  2  0  2  0  0  4 10  0  0 22  0  0  0 10  7  0\n",
      " 10  0  0 30  5 10 10  0 17  0  5  0  4  0 21  0  0  0  0  0  9  0 15 10\n",
      "  0  0 10 10  8 25  0  0  0  0  0  4  0 22  0  0  4  0 10  0  0  1  4 20\n",
      "  0  4  0  6  0  0 10  0 23 10  5 19  0  2  0  0  7 10 16  0  0  0  0  5\n",
      "  4  5  4  4  0 10 11  0  0  0  0  0 32  0  4  0 14 33  0  2 23  9 10 24\n",
      "  0  0 20 15 15  0  0  2  7  2  0 15  0  0  9  0 20  8  2  0  0  6  2  8\n",
      "  0  0  0 25  0  0 17 24 10  0  0  0  0 15 20  0  0 33 10  0  0 33 10  2\n",
      "  0 17  0 10  0 10  0  2  0 21  0  0  0  0 10 11 10  0  0 10  5  6 10  0\n",
      "  0 15 10  0 21  0  0  0  0 20 10 27  0  0  4  4  0  0  2 15  4 21  2  4\n",
      "  0  0  0  0  0  0  0 10  0  2  0 10  0  2  2  7  0  0  0  0  2  5  8  4\n",
      " 20 10 17 24  0  0  4  4  4  0  0  0  0 15  0  6 21 20  0  0  7  0  0  0\n",
      "  0  4  0  2  6  6 15  8  5 10  6 10  0  9  0  0  0  0  4  0  0  0  4  4\n",
      " 20 10 33  0  0  0 20 17 14  0  5  0  0  2 10 21  0 17  7  1  0  2 10  0\n",
      "  0  2  2  8  0  0  0 15  0  0  0  0 12  0  0  0  0  0  7  0 35 21  0  0\n",
      "  0 10  0  4  2  0  0  4  0  4  0 17 17  0 10  0  7  4  0  0  4 10  0  0\n",
      " 20  0  0  0  0  0  0  4 12  0  0  9  0  0  4 30  0  0  0  0  4 10  9 20\n",
      "  0 10  0 10  0  0  4 20  0 17  0  0 10  0 33  0  0  0 21  0  0  7  4 14\n",
      "  7  0  0  0  0  8 10  0  0  0 10  2  0 21  0  0  0 14  0  0  4  5  0  0\n",
      "  0  0  0 20  9  0  0  0  0 15  0  0 10 27  0 22  1  0  2  0 33  0 10 10\n",
      "  5  0  0  0  0  2  6 24  6  0 10  0  0 10 10  4 10  0  0 10 10 33 10 10\n",
      "  0 33 10  0  4  0  0  0  6  0 10 10  6  2  0  2  0  0 25 10  0  2  2  0\n",
      "  6 23  0  0  0  0  9  0  0 10  0  0  7  0 10  4  4  0  6  0  4  0 15  8\n",
      "  2  0  0  4  0  0  2 15  0  4 10  0 10  0  0  4  0 10  0  0  0  0  0 10\n",
      "  5  4  0  0 21  2  0 22  0  6 11  0 10 10  0  4]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for path in paths:\n",
    "    results.append(np.load(path))\n",
    "    \n",
    "print(np.array(results).sum(axis=0).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d2087e6-33d4-42be-a9b8-4e4679672c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(np.array(results).sum(axis=0).argmax(axis=1), columns=['pred'])\n",
    "output.to_csv('/opt/ml/submission_{}.csv'.format(\"ensemble_all\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0395e0c0-d578-420b-9fa3-3b50a26cd7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    '/opt/ml/logits/logit_roberta_leaderboard_large.npy', #32\n",
    "    '/opt/ml/logits/logit_koelectra-epoch-20.npy', #28\n",
    "    '/opt/ml/logits/logit_model_skt-kobert-both-label.npy', #20\n",
    "    '/opt/ml/logits/logit_roberta_large-seed-26.npy',\n",
    "    '/opt/ml/logits/logit_bert-seed-7-epoch-20.npy', #29\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8abcb8fb-3aec-499e-8949-2a65a8e4d736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 10  1  0  0  0  7 28  4 20  0  0  0  8  0  0  0  0  0 10 15  5  0 27\n",
      "  4  4 10  0  0 21  0  4 10  8 23  0 21  4  0  0  0  0  0 25 17  0  9  2\n",
      "  0 15  0 10  0  2  0 15 39  0  0 10  0 33  0 17  4  2 24 21 12  0  0  0\n",
      "  0 10  0  0  2 15 14  0 15  0  0 10 15  0  4  6  7  2  5 12  0 17 21  0\n",
      "  8 14 15 15 15  2  0 21  7  0  0  7  0  0  0  2  0  0  4  0  2  0  0  0\n",
      "  0 15  6  0  4 20  7  0 10 15  0  0  0  0 10  0 20  0  4  0  0 10  0 10\n",
      "  0 15  0 10  0  9 10 21  2  8  0  0 17  0  0  0  0  0  0 10  0 10  9  8\n",
      "  0  0 10  0  0 20 17  0  0 27  2  0  2  0 39  2 22  0  9 10  0 25  0  5\n",
      " 32 20 10  0 11 10  0 15 21 24  2  0  4  0  0 27  0 10 10  7 15  0  4  5\n",
      "  0  5 15  0  0  0  0 10  8  0  0  2  0  4 27  4  0  0  0  0  0  0 10  0\n",
      " 10  0  0  0 22  0  5  0  7 21  0  0  5  5  5  8  6 10 17  0  2 17  6  4\n",
      "  4  0  0  0 15  0 15  0  2  7 22 10  0  8  0  0  4  8 25  2  0 10  0 10\n",
      "  8  2 15  2  0 10 21  0  0  0 10  0  8  0  4  4  7  0  2  4  0  0  0  0\n",
      "  4  0  0 15  0 15 10  6  0  0  0  4 22 15  4  0  2  8  0  4 24  0 10  4\n",
      "  0 10  0 33  0  0  0 24 34  0  0  0  0 27  2  2 10  0  0  4  2  0  0  0\n",
      " 17  7  0 35  0 10 12 32  4  0  0  0 10  0  0  4  7  0  0  8  0  0 15  0\n",
      " 15  0  4  0  0 10 15  0 11  3  2  0  4  0 20  0  4  0  0  0  0  0 17  5\n",
      "  4 11  4  0  0  0  0  2  8 10 12  0  0  0  0  0  0  2  4  0  4  0  0 10\n",
      "  0  0  0 34  0  0  0 10  2  0  2  7  0  4 10  0  0 22 22  2 33 10  0  0\n",
      " 10  0  0 30  5 10 10  0 17  0  5  0  4  0 21  0  0  0  0  0  9  0 15 10\n",
      "  0  0 10 10  8 25  0  0  0  0  0  0  0 22  0  0  4  0 10  0  0  1  4 20\n",
      "  0  4  0  6 17  0 10  0 23 10  5 19  0  2  0  0  7 10 16  0  0  0  0  5\n",
      "  0  5  4  4  0 10 11  0  0  0  0  0 32  0  4  0 14 33  0  2 23  9 10 24\n",
      "  0  0 20  0 15  0  0  2  7  2  0 15  6 32  9  0 20  8  2  0  0  6  2  8\n",
      "  0  0  0 25  0  0 17 24 10  0  0  0  0 15 20  0  0 33 10  1  0 33 10  2\n",
      "  9 17  0 10  0 10  0  2  0 21  0  0  0  0 10 11 10  0  0 10  0 23 10  0\n",
      "  0 15 10  0 21  0  0  0  0 20 10 27  0  0  4  4  0  0  2 15  4 21  2  4\n",
      "  0  0  0  0  0  0  0 10  5  2  0 10  0  0  2  7  0  0  0  0  2  5  8  4\n",
      " 20 10 17 24  0  0  4  4  4  0  0  0  0 15  0  6 21 20 10  0  7  0  0  0\n",
      "  0  4  0  2  6  6 15  8  5 10  6 10  0  9  0  0  0  0  4  0  0  0  4  4\n",
      " 20 10 33  0  0  0 20 17 14  0  5  0  0  0 10 21  0 17  7  1  0  2 10  0\n",
      "  0  2  2 21  0  0 23 15  0  0  0  0 12  0 20  0  0  0  7  0  0 21  0 15\n",
      "  0  0  0  4  2  0  0  4  0  4  0 17 17  0 10  0  7  4  0  0  4 10  0  0\n",
      " 20  0  0  0  0  0  0  4 12  0  0  9  0  0  4 30  0  0  0  0  4 10  9 20\n",
      "  0 10  0 10  0  0  4 20  0 17  0  0 10  0 33  0  0  0 21  0  0  7  4 14\n",
      "  7  0  0  0  0  8 10  0  0  0 10  2  0 21  0  0  0 14  0  0  0  5  0  0\n",
      "  0  0  0 20  9  0  0  0  0  0  0  0 10 27  0 22  1  0  0  0 33  0 10 10\n",
      "  5  0  0  0  0  0  6 24  6  0 10  0  0 10 10  4 10  0  0 10 10 33 10 10\n",
      "  0 33 10  0  4  0  0  0  6  0 10 10  6  2  0  2  0  0 25 10  0  2  2  0\n",
      "  6 23  0  0  0  0  9 25  0 10  0  0  7  0 10  4  4  0  6  0  4  0 15  1\n",
      "  2  0  0  4  0  0  2 15 17  4 10  0 10  0  0  7  0 10  5  0  0  0  0 10\n",
      "  5  4  0  0 21  2  0 22  0  6 11  0 10 10  0  0]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for path in paths:\n",
    "    results.append(np.load(path))\n",
    "    \n",
    "print(np.array(results).sum(axis=0).argmax(axis=1))\n",
    "output = pd.DataFrame(np.array(results).sum(axis=0).argmax(axis=1), columns=['pred'])\n",
    "output.to_csv('/opt/ml/submission_{}.csv'.format(\"ensemble_top_5\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c462e4-12c7-4a40-b725-815ef36f3fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
